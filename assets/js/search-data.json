{
  
    
        "post0": {
            "title": "Simple SLURM Tutorial",
            "content": "Submitting Jobs with SLURM . srun is used to submit a job for execution or initiate job steps in real time. srun has a wide variety of options to specify resource requirements . Example . The command hostname ouputs the hostname and domain of the system it is run on in the following format: hostname.domain. . Try it for yourself: . $ hostname . Now we can try submitting a SLURM job that can run this command on our available resources in various ways. . First, execute /bin/hostname in six tasks with the -n6 option: . $ srun -n6 -l hostname . Note: the -l option prepends the lines of output with the task number . Next, execute /bin/hostname on three separate nodes with the -N3 option: . $ srun -N3 -l hostname . Now try both options together and notice that the default behavior is to divy up the tasks equally among the nodes. . These are just two of the many different ways to specify resource requirements including: minimum and maximum node count, processor count, and specific nodes to use or not use. We will learn more about these options as we go along, but a complete list can be found here. . Now we aren’t on this cluster all by ourselves, so typically we want to submit a job or a series of jobs to the queue to wait it’s turn in line to be executed. sbatch is used to submit a job script for later execution. The script will typically contain one or more srun commands to launch parallel tasks. . For example, we can submit our last exaple job to the queue with the following script: . #!/bin/bash #SBATCH -J first_example # Job Name #SBATCH --time=00:00:30 # Walltime #SBATCH -o output.txt # The destination file for stdout #SBATCH -e error.txt # The destination file for stderr srun hostname srun echo &quot;whatever&quot; . This naming schema for output and errors isn’t always ideal, because subsequent submission of this script will overwrite these files. To prevent this, we can use replacement symbols to customize the filename patterns. Here are some common ones: . %j - jobid of the running job. . %n - Node identifier relative to current job (e.g. “0” is the first node of the running job) This will create a separate IO file per node. . %t - task identifier (rank) relative to current job. This will create a separate IO file per task. . %u - User name. . %x - Job name. . For example we can change the output and error files to include the jobID unique to each submission. . #SBATCH -o jobID_%j.o # The destination file for stdout #SBATCH -e jobID_%j.e # The destination file for stderr . This way we can remove these files relating to one job in particular very easily. Say the jobID of our last job was 292. We can easily remove the files for this run (but not others) by calling: . $ rm jobID_292* . Or if we want to list the files in numeric order we can use the command: . $ ls | sort -n -t _ -k 2 . The sort command has lot of options that makes manipulating token separated file schemas very easily. The -n flag indicates the sort should be strictly numeric. The -t _ option specifies that sections are separated by underscores, and the -k 2 option indicates that the second “chunk” in between the underscores is the one we want to sort by. . If you are unfamiliar with the pipe symbol (|), refer to this tutorial. . Performance Tuning . In this section, we will learn about how our cluster architecture influences our resource requirements and runtime performance. . Terminology . A node contains one or more sockets. 4 . | A socket is a receptacle on the motherboard for exactly one processor. 2 . | A processor contains one or more (CPU) cores. 20 . | For our purposes, a one task is usually assigned to each CPU. (If not the -c option can be used to specify cores per task. . | . . We want to know about Haynes specifically. SLURM has the following command that provides us with useful information about the hardware on our nodes. . $ scontrol show node . First, you will notice that we have five nodes. Next, take note of CoresPerSocket, Sockets, Boardsand ThreadsPerCore. . CoresPerSocket=20 Sockets=2 Boards=1 ThreadsPerCore=1 . We can verify that cpu=40 by working out the fractions, $ frac{1 text{ motherboard}}{ text{Node}} frac{2 text{ sockets}}{ text{motherboard}} frac{ 20 text{ cores}}{ text{socket}}= frac{40 text{ cores}}{ text{node}}$ . . ***Running . tpv33_receivers.dat ‘tpv33_initial_stress.yaml’ tpv33_faultreceivers.dat’ ‘output/data’ . . %A - Job array’s master job allocation number. . %a - Job array ID (index) number. . %J - jobid.stepid of the running job. (e.g. “128.0”) . %N - short hostname. This will create a separate IO file per node. . %s - stepid of the running job. . #!/bin/bash #SBATCH -J array_job #SBATCH -o jobID_%A_taskID_%a.out #SBATCH -e jobID_%A_taskID_%a.err #SBATCH -t 00:05:00 #SBATCH --array=1-20 #SBATCH -n 1 echo &quot;SLURM_ARRAY_TASK_ID is $SLURM_ARRAY_TASK_ID&quot; &gt;&gt; result_$SLURM_ARRAY_JOB_ID.out echo &quot;Waiting $SLURM_ARRAY_TASK_ID seconds...&quot; echo &quot;All done!&quot; .",
            "url": "https://nicole-brewer.com/catch-me-coding/markdown/2020/02/25/simple-slurm-tutorial.html",
            "relUrl": "/markdown/2020/02/25/simple-slurm-tutorial.html",
            "date": " • Feb 25, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Introduction to Docker",
            "content": "What is Docker? . If you’ve never worked with containers or VM’s before, understanding what Docker is and does might be a little hard to wrap your mind around. You can start by thinking about it as a solution to a problem: you want to run code that can be tested or deployed anywhere, regardless of the machine or OS you’re using. Docker fixes this problem by creating a layer on top of your machine’s resources that simulates the OS you want. This way, when the layer is deployed, you know you can install whatever dependencies you need in a consistent way across machines. Therefore you only have to build an application in one way to be able to run it on any kind of machine. . Building the Image . An image is an executable package that includes everything needed to run an application–the code, a runtime, libraries, environment variables, and configuration files. . A container is a runtime instance of an image. . A Dockerfile defines what goes on in the environment inside your container. Dockerfile’s have the following format options: . # All Dockerfiles must specify a base image FROM &lt;base image&gt; MAINTAINER # Note: subsequent references to defined environment # variables can be made by $&lt;key&gt; or ${&lt;key&gt;} ENV &lt;key&gt; &lt;value&gt; ENV foo /bar # RUN executes commands on top of the current image and commits the # result. In shell form... RUN &lt;shell command&gt; # exec form... (note that the variable isn&#39;t processed and we have # to throw in an echo statement) RUN [&quot;executable&quot;, &quot;params&quot;, &quot;echo $SOME_VAR&quot;] # To use a different shell... RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] # Both ENTRYPOINT and CMD give you a way to identify which executable # should be run when a container is started from your image. You must # include at least one. CMD is easier to override and should be used # when you want flexability in the executable that is run when # starting the container. CMD can be used to specify default options # for ENTRYPOINT (must use exec form for that). CMD [&quot;executable&quot;, &quot;param&quot;] # LABELs are used to add metadata and can be viewed with the # &#39;docker inspect&#39; command LABEL &lt;key&gt;=&lt;value&gt; LABEL multi.label1=&quot;value1&quot; multi.label2=&quot;value2&quot; other=&quot;value3&quot; # The MAINTAINER instruction sets the Author field of the generated # images. The LABEL instruction is a much more flexible version of # this and you should use it instead MAINTAINER &lt;name&gt; LABEL maintainer=&quot;brewer36@purdue.edu&quot; # EXPOSE informs Docker that the container listens on the specified # network ports at runtime EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...] EXPOSE 80/tcp # The COPY instruction copies new files or directories from &lt;src&gt; # and adds them to the filesystem of the container at the path # &lt;dest&gt;. The --chown flag requests specific ownership of the # content added. If you want to specify a user for all RUN, CMD, and # ENTRYPOINT instructions, use the USER command USER &lt;UID&gt;[:&lt;GID&gt;] COPY &lt;src&gt; &lt;dest&gt; # or... COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt; # ADD is like copy but allows &lt;src&gt; to be a URL or automatically unpack &lt;src&gt; if its compressed ADD http://example.com/foobar / # The WORKDIR instruction sets the working directory for any RUN, # CMD, ENTRYPOINT, COPY and ADD instructions that follow it. If a # relative path is provided, it will be relative to the path of the # previous WORKDIR instruction WORKDIR /path/to/workdir # defines a variable that users can pass at build-time to the builder # with the docker build command using the # --build-arg &lt;varname&gt;=&lt;value&gt; flag ARG &lt;name&gt;[=&lt;default value&gt;] . We use the build command to create a Docker image: . docker build -t &lt;tagname&gt; . If we want to upload this image public on a certain registry (associated with a Docker account), we tag the image as follows: . docker tag image username/repository:tag . and then push it to the repo: . docker push username/repository:tag . Running the App . We can then run the app in the the container defined by the image: . docker run -d -p 4000:80 &lt;tagname&gt; . Note: The -d option runs the app in the background (detatched mode) and the -p maps the local port to the container’s published port. . You can check to see what containers are running with… . docker container ls . …and they can be stopped with… . docker container stop &lt;container name or id&gt; .",
            "url": "https://nicole-brewer.com/catch-me-coding/markdown/2020/02/25/introduction-to-docker.html",
            "relUrl": "/markdown/2020/02/25/introduction-to-docker.html",
            "date": " • Feb 25, 2020"
        }
        
    
  

  
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nicole-brewer.com/catch-me-coding/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}